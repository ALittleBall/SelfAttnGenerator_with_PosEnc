# SelfAttnGenerator_with_PosEnc

Based on EdgeConnect paper. The Generator only use 
convolution layers in the generator. Though 
convolution can increase limited the receptive field, 
each pixel cannot have a global view of all the image.

This code adds self attention layers in the generator
network. Also the position encoding and multihead
attention are added in the self attention layers.

The reason why I add position encoding in the attention 
is that I think relative position of each pixel is also 
important, to help concentrate on adjacent pixels. Or 
the pixels may pay much less important attention to the 
irrelevant area. And this may cause GAN to generate 
the inpainting area negatively affected by the pixels
far away from the mask.

The updated formula is:
![https://github.com/ALittleBall/SelfAttnGenerator_with_PosEnc/blob/master/IMG/formular.png]

P is position matrix, generated by the relative position 
of the target pixel. The relative coordinate can 
be calculated from the index of column and the row of the 
Q MatMul K.T matrix. As shown in the pseudocode.

![https://github.com/ALittleBall/SelfAttnGenerator_with_PosEnc/blob/master/IMG/pseu.png]

Also, to improve the generalization of the attention layer, the 
multihead method is applied. So the attention layer looks like.

![https://github.com/ALittleBall/SelfAttnGenerator_with_PosEnc/blob/master/IMG/attn.png]

I insert several layer in the generator:

![https://github.com/ALittleBall/SelfAttnGenerator_with_PosEnc/blob/master/IMG/gen.png]

With the improvement in Self Attention layers, I applied it in the model in EdgeConnect 
GAN Network, it can avoid the bad cases below.

![https://github.com/ALittleBall/SelfAttnGenerator_with_PosEnc/blob/master/IMG/pos.png]

(LeftUp) This image is the ground truth. (RightUp) This
image is generated from the model that does not encode the position
information. (LeftDown) The masked image as input of the
model. (RightDown) This image is generated from the model with
position encoding. It can easily find out that the position encoding
could help the pixel to concentrate on the pixels nearby.

The general output of the test image shown:



Reference:

@misc{zhang2018selfattention,
    title={Self-Attention Generative Adversarial Networks},
    author={Han Zhang and Ian Goodfellow and Dimitris Metaxas and Augustus Odena},
    year={2018},
    eprint={1805.08318},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{nazeri2019edgeconnect,
    title={EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning},
    author={Kamyar Nazeri and Eric Ng and Tony Joseph and Faisal Z. Qureshi and Mehran Ebrahimi},
    year={2019},
    eprint={1901.00212},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
